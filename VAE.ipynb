{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyfGcNY4pcXd"
      },
      "source": [
        "# Homework2: Variational inference and VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvqXOhwQf0c2"
      },
      "source": [
        "## Task 1: Theory (5pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07321QwCf0c3"
      },
      "source": [
        "### Problem 1: IWAE theory (1pt)\n",
        "\n",
        "In Lecture 3 we discussed [IWAE](https://arxiv.org/abs/1509.00519) model. This model introduces the improved version of the variational lower bound (ELBO):\n",
        "\n",
        "$$\n",
        "    \\mathcal{L}_K (q, \\boldsymbol{\\theta})  = \\mathbb{E}_{\\mathbf{z}_1, \\dots, \\mathbf{z}_K \\sim q(\\mathbf{z} | \\mathbf{x})} \\log \\left( \\frac{1}{K}\\sum_{k=1}^K\\frac{p(\\mathbf{x}, \\mathbf{z}_k | \\boldsymbol{\\theta})}{q(\\mathbf{z}_k| \\mathbf{x})} \\right) \\rightarrow \\max_{q, \\boldsymbol{\\theta}}.\n",
        "$$\n",
        "\n",
        "Here we had the theorem without proof:\n",
        "\n",
        "1. $\\log p(\\mathbf{x} | \\boldsymbol{\\theta}) \\geq \\mathcal{L}_K (q, \\boldsymbol{\\theta}) \\geq \\mathcal{L}_M (q, \\boldsymbol{\\theta}), \\quad \\text{for } K \\geq M$;\n",
        "2.  $\\log p(\\mathbf{x} | \\boldsymbol{\\theta}) = \\lim_{K \\rightarrow \\infty} \\mathcal{L}_K (q, \\boldsymbol{\\theta})$ if $\\frac{p(\\mathbf{x}, \\mathbf{z} | \\boldsymbol{\\theta})}{q(\\mathbf{z} | \\mathbf{x})}$ is bounded.\n",
        "\n",
        "Now it is time to prove it :)\n",
        "\n",
        "**Hints:**\n",
        "1. First part of the theorem.\n",
        "\n",
        "    (a) Use the following equation inside the logarithm of $\\mathcal{L}_K (q, \\boldsymbol{\\theta})$\n",
        "$$\n",
        "    \\frac{a_1 + \\dots + a_K}{K} = \\mathbb{E}_{k_1, \\dots, k_M} \\frac{a_{k_1} + \\dots + a_{k_M}}{M}, \\quad k_1, \\dots, k_M \\sim U[1, K]\n",
        "$$\n",
        "    (b) Apply Jensen' inequality.\n",
        "3. Second part of the theorem: use the Law of large numbers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J37lldMf0c3"
      },
      "source": [
        "```\n",
        "посчитал у себя в тетрадки\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAVwmi2of0c4"
      },
      "source": [
        "### Problem 2: EM-algorithm for GMM (4pt)\n",
        "\n",
        "**Do not worry:** the task is long-written, but it is very useful for the understanding of the EM-algorithm and it is not very hard :)\n",
        "\n",
        "Recall the Gaussian Mixture Model (GMM) we discussed in Seminar 3:\n",
        "\n",
        "- model parameters $\\boldsymbol{\\theta} = \\{ \\boldsymbol{\\pi}_{1:K}, \\boldsymbol{\\mu}_{1:K}, \\boldsymbol{\\Sigma}_{1:K} \\}$;\n",
        "\n",
        "- prior distribution (note that here it also depends on $\\boldsymbol{\\theta}$) $p(z | \\boldsymbol{\\theta}) = \\text{Categorical}(\\pi_1, \\dots \\pi_K)$;\n",
        "\n",
        "- generative distribution $p(\\mathbf{x} | z, \\boldsymbol{\\theta}) = \\mathcal{N}\\left(\\mathbf{x}|, \\boldsymbol{\\mu}_z, \\boldsymbol{\\Sigma}_z\\right)$.\n",
        "\n",
        "Given samples $\\mathbf{X} = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_n\\} \\sim p(\\mathbf{x})$ , $\\mathbf{x}_i \\in \\mathbb{R}^m$ we want to fit GMM model via **MLE**:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\theta}^{*} = \\arg\\max\\limits_{\\boldsymbol{\\theta}} \\log p(\\mathbf{X} | \\boldsymbol{\\theta}) = \\arg\\max\\limits_{\\boldsymbol{\\theta}}\\sum\\limits_{i = 1}^{n} \\log \\left(\\sum\\limits_{k = 1}^{K}  \\pi_k \\mathcal{N}\\left(\\mathbf{x} | \\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k\\right)\\right).\n",
        "$$\n",
        "\n",
        "The direct solution of the problem above is hard and we substitute **MLE** optimization with **ELBO** optimization:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\theta}^{\\#} = \\arg\\max\\limits_{q, \\boldsymbol{\\theta}} \\mathcal{L}(q, \\boldsymbol{\\theta}) = \\arg\\max\\limits_{q, \\boldsymbol{\\theta}} \\int\\limits_{Z^n} q(z_1, \\dots, z_n) \\log\\frac{ p(\\mathbf{x}_1, z_1, \\dots, \\mathbf{x}_n, z_n | \\boldsymbol{\\theta}) }{ q(z_1, \\dots, z_n) } \\prod\\limits_{i = 1}^{n} d z_i.\n",
        "$$\n",
        "\n",
        "Since the pairs $(\\mathbf{x}_1, z_1), \\dots ,(\\mathbf{x}_N, z_n)$ are mutually independent, the distributions could be factorized:\n",
        "$$\n",
        "    q(z_1, \\dots, z_n) = \\prod_{i=1}^n q(z_i); \\quad p(\\mathbf{x}_1, z_1, \\dots, \\mathbf{x}_n, z_n | \\boldsymbol{\\theta}) = \\prod_{i=1}^n p(\\mathbf{x}_i, z_i | \\boldsymbol{\\theta}).\n",
        "$$\n",
        "$$\n",
        "\\mathcal{L}(q, \\boldsymbol{\\theta}) = \\sum\\limits_{i = 1}^{n} \\int\\limits_{Z} q(z_i) \\log\\frac{ p(\\mathbf{x}_i, z_i | \\boldsymbol{\\theta}) }{ q(z_i) } d z_i.\n",
        "$$\n",
        "\n",
        "In the equations above we treet $q(\\cdot)$ as continuous density function. In our case $q(\\cdot)$ is discrete categorical distribution and all integrals are substituted with the corresponding sums:\n",
        "\n",
        "$$\n",
        "\\int\\limits_{Z} f(z) q(z) dz \\longrightarrow \\sum\\limits_{k = 1}^{K} f(k) q(\\{z = k\\}).\n",
        "$$\n",
        "\n",
        "**ELBO** optimization could be done via EM-algorithm:\n",
        "\n",
        "#### EM-algorithm\n",
        "\n",
        "* **E-step**\n",
        "\n",
        "    $$\n",
        "    q(z_i) = p(z_i | \\mathbf{x}_i, \\boldsymbol{\\theta}^{\\text{prev}}).\n",
        "    $$\n",
        "    \n",
        "    Note, that $q(z_i)$ is a categorical distribution over $K$ components: $q(z_i) = \\text{Categorical}(\\xi_1^i, \\xi_2^i, \\dots, \\xi_K^i)$.\n",
        "\n",
        "* **M-step**\n",
        "\n",
        "    \\begin{align}\n",
        "    \\boldsymbol{\\theta}^{\\text{new}} &= \\arg\\max\\limits_{\\boldsymbol{\\theta}} \\sum\\limits_{i = 1}^{n} E_{z_i \\sim q(z_i)} \\log p(\\mathbf{x}_i, z_i | \\boldsymbol{\\theta}) \\\\\n",
        "    &= \\arg\\max\\limits_{\\boldsymbol{\\theta}}  \\sum\\limits_{i = 1}^{n} \\sum\\limits_{k = 1}^{K} q(\\{z_i = k\\}) \\log p(\\mathbf{x}_i, \\{z_i = k\\} | \\boldsymbol{\\theta}).\n",
        "    \\end{align}\n",
        "    \n",
        "#### E- and M- steps derivations\n",
        "    \n",
        "Recall the derivation of **E-step** from the class:\n",
        "\n",
        "$$\n",
        "q(\\{z_i = k\\}) = \\xi_k^i = p(\\{z = k\\} | \\mathbf{x}_i, \\boldsymbol{\\theta}^{\\text{prev}}) \\overset{\\text{Bayes theorem}}{=} \\frac{\\pi_k \\mathcal{N}(\\mathbf{x}_i | \\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k)}{\\sum\\limits_{k' = 1}^{K} \\pi_{k'} \\mathcal{N}(\\mathbf{x}_i | \\boldsymbol{\\mu}_{k'}, \\boldsymbol{\\Sigma}_{k'})}.\n",
        "$$\n",
        "\n",
        "**M-step** is a bit harder. Let's denote\n",
        "\n",
        "$$\n",
        "\\Phi\\left(\\boldsymbol{\\pi}_{1:K}, \\boldsymbol{\\mu}_{1:K} , \\boldsymbol{\\Sigma}_{1:K}\\right) := \\sum\\limits_{i = 1}^{n} \\sum\\limits_{k = 1}^{K} q(\\{z_i = k\\}) \\log p(\\mathbf{x}_i, \\{z_i = k\\} | \\boldsymbol{\\theta}) =\\\\= \\sum\\limits_{i = 1}^{n} \\sum\\limits_{k = 1}^{K} \\xi_k^i \\left(\\log \\pi_k - \\frac{m}{2} \\log 2 \\pi - \\frac{1}{2} \\log \\det \\boldsymbol{\\Sigma}_k - \\frac{1}{2} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k)^T \\boldsymbol{\\Sigma}_k^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k)\\right).\n",
        "$$\n",
        "\n",
        "Let's maximize $\\Phi(\\cdot)$ with respect to parameters $\\boldsymbol{\\pi}_{1:K}$, $\\boldsymbol{\\mu}_{1:K}$, $\\boldsymbol{\\Sigma}_{1:K}$ separately:\n",
        "\n",
        "1. Maximization with respect to $\\boldsymbol{\\pi}_{1:K}$:\n",
        "$$\n",
        "\\arg\\max\\limits_{\\boldsymbol{\\pi}_{1:K}; \\, \\pi_k > 0 \\\\ \\sum\\limits_{k = 1}^{K} \\pi_k = 1} \\Phi\\left(\\boldsymbol{\\pi}_{1:K}, \\boldsymbol{\\mu}_{1:K} , \\boldsymbol{\\Sigma}_{1:K}\\right) = \\arg\\max\\limits_{\\boldsymbol{\\pi}_{1:K}; \\, \\pi_k > 0 \\\\ \\sum\\limits_{k = 1}^{K} \\pi_k = 1} \\sum\\limits_{i = 1}^{n} \\sum\\limits_{k = 1}^{K} \\xi_k^i \\log \\pi_k = \\arg\\max\\limits_{\\boldsymbol{\\pi}_{1:K}; \\, \\pi_k > 0 \\\\ \\sum\\limits_{k = 1}^{K} \\pi_k = 1} \\sum\\limits_{k = 1}^{K} \\log \\left(\\pi_k \\right) \\sum\\limits_{i = 1}^{n} \\xi_k^i.\n",
        "$$\n",
        "\n",
        "    **Subproblem 2.1 (1.5pt):** Prove, that the $\\arg\\max$ problem above has solution $\\pi_k^{\\text{new}} = \\frac{\\sum\\limits_{i = 1}^{n} \\xi_k^i}{n}$, $k \\in 1, 2, \\dots K$.\n",
        "    \n",
        "2. Maximization with respect to $\\boldsymbol{\\mu}_{1:K}$. Let's take the derivative:\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\boldsymbol{\\mu}_k} \\Phi\\left(\\boldsymbol{\\pi}_{1:K}, \\boldsymbol{\\mu}_{1:K} , \\boldsymbol{\\Sigma}_{1:K}\\right) = \\frac{\\partial}{\\partial \\boldsymbol{\\mu}_k} \\sum\\limits_{i = 1}^{n} - \\frac{\\xi_{k}^{i}}{2} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k)^T \\boldsymbol{\\Sigma}_k^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k) = \\sum\\limits_{i = 1}^{n} \\left(\\boldsymbol{\\Sigma}_k^{-1} \\mathbf{x}_i - \\boldsymbol{\\Sigma}_k^{-1} \\boldsymbol{\\mu}_k\\right) \\xi_k^i = \\boldsymbol{\\Sigma}_k^{-1} \\sum\\limits_{i = 1}^{n} \\left(\\mathbf{x}_i - \\boldsymbol{\\mu}_k\\right) \\xi_k^i = 0.\n",
        "$$\n",
        "\n",
        "    Since $\\boldsymbol{\\Sigma}_k^{-1}$ is positive definite, the equation above could be written as follows:\n",
        "    \n",
        "$$\n",
        "\\sum\\limits_{i = 1}^{n} \\left(\\mathbf{x}_i - \\boldsymbol{\\mu}_k\\right) \\xi_k^i = 0 \\quad \\Rightarrow \\quad \\boldsymbol{\\mu}_k^{\\text{new}} = \\frac{\\sum\\limits_{i = 1}^{n} \\mathbf{x}_i \\xi_k^i}{\\sum\\limits_{i = 1}^{n} \\xi_k^i}.\n",
        "$$\n",
        "    \n",
        "3. Maximization with respect to $\\boldsymbol{\\Sigma}_{1:K}$.\n",
        "\n",
        "    **Subproblem 2.2 (1.5pt):** Prove, that  \n",
        "$$\n",
        "\\boldsymbol{\\Sigma}^{\\text{new}}_k = \\frac{1}{\\sum\\limits_{i = 1}^{n} \\xi_k^i} \\sum\\limits_{i = 1}^{n} \\xi_{k}^{i} \\left(\\mathbf{x}_i - \\boldsymbol{\\mu}^{\\text{new}}_k\\right) \\left(\\mathbf{x}_i - \\boldsymbol{\\mu}^{\\text{new}}_k\\right)^T.\n",
        "$$\n",
        "\n",
        "    *Hint 1*: $\\frac{\\partial}{\\partial \\mathbf{A}} \\det \\mathbf{A} = \\left( \\det \\mathbf{A} \\right) (\\mathbf{A}^{-1})^T$.\n",
        "    \n",
        "    *Hint 2*: $\\frac{\\partial}{\\partial \\mathbf{A}} \\mathbf{x}^T \\mathbf{A}^{-1} \\mathbf{y} = - (\\mathbf{A}^{-1})^T \\mathbf{x} \\mathbf{y}^T (\\mathbf{A}^{-1})^T$.\n",
        "    \n",
        "    *General Hint*: there is a nice book that helps in working with matrices [matrixcookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf).\n",
        "    \n",
        "    **Subproblem 2.3 (1pt):** Prove, that $\\frac{\\partial}{\\partial \\mathbf{A}} \\det \\mathbf{A} = \\left( \\det \\mathbf{A} \\right) (\\mathbf{A}^{-1})^T$.\n",
        "\n",
        "    *Hint*: Recall the notion of *cofactor* or *adjunct* (алгебраическое дополнение) ([wiki_en](https://en.wikipedia.org/wiki/Minor_(linear_algebra)), [wiki_ru](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%B4%D0%BE%D0%BF%D0%BE%D0%BB%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)) from Linear Algebra courses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXAGekFBf0c4"
      },
      "source": [
        "```\n",
        "посчитал у себя в тетрадки\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9leRbWNBqZM2"
      },
      "outputs": [],
      "source": [
        "REPO_NAME = \"2023-DGM-MIPT-course\"\n",
        "!if [ -d {REPO_NAME} ]; then rm -Rf {REPO_NAME}; fi\n",
        "!git clone https://github.com/r-isachenko/{REPO_NAME}.git\n",
        "!cd {REPO_NAME}\n",
        "!pip install ./{REPO_NAME}/homeworks/\n",
        "!rm -Rf {REPO_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc5RAWFOqekr"
      },
      "outputs": [],
      "source": [
        "from dgm_utils import train_model, plot_training_curves\n",
        "from dgm_utils import show_samples, visualize_images, load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIBqEphlrEGd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Optional\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN3th9zXANgx"
      },
      "source": [
        "## Task 2: VAE on CIFAR10 data (4pt)\n",
        "\n",
        "In this task you will implement VAE model for CIFAR10 dataset.\n",
        "\n",
        "Let download and visualize samples from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POBb7efUAQhp"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = load_dataset(\"cifar10\", flatten=False, binarize=False)\n",
        "visualize_images(train_data, \"CIFAR10 samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biYy9_rWd-DY"
      },
      "source": [
        "Now it is time to define our model. Our model will have the following structure:\n",
        "\n",
        "* Prior distribution is standard Normal ($p(\\mathbf{z}) = \\mathcal{N}(0, I)$).\n",
        "* Variational posterior distribution (or encoder) is $q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x}))$. Here $\\boldsymbol{\\phi}$ denotes all parameters of the encoder neural network. We will assume that covariance matrice $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x})$ is diagonal.\n",
        "* Generative distribution (or decoder) is $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))$. Here $\\boldsymbol{\\theta}$ denotes all parameters of the decoder neural network. Please note, that here we will use continuous distribution for our variables $\\mathbf{x}$.\n",
        "* We do not fit the covariance matrix $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ in the generative distribution $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$. We assume that it is identical ($\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\mathbf{I}$). We will use the $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ (means of the generative distribution $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$) as model samples.\n",
        "* Our encoder and decoder will be convolutional neural networks.\n",
        "* Model objective is slightly modified ELBO:\n",
        "$$\n",
        "    \\mathcal{L}(\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\mathbb{E}_{q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) - \\beta * KL (q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) || p(\\mathbf{z})).\n",
        "$$\n",
        "Here we introduce the parameter $\\beta$. It reweights KL term in the total loss. It a standard heuristics that allows to get more accurate model. In this exercise you have to play with it, starting with the value $\\beta = 1$ (standard ELBO).\n",
        "\n",
        "To make the expectation is independent of parameters $\\boldsymbol{\\phi}$, we will use reparametrization trick.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxqxyXZBbKfy"
      },
      "source": [
        "To calculate the loss, we should derive\n",
        "- $\\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$, note that generative distribution is $\\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))$.\n",
        "- KL between $q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x}))$ and $\\mathcal{N}(0, \\mathbf{I})$.\n",
        "\n",
        "Let start with the helper functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWxeHOhqPMqz"
      },
      "source": [
        "\\begin{align}\n",
        "KL(p, q) = \\log \\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2 \\sigma_2^2} - \\frac{1}{2}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZEUyHuxE39I"
      },
      "outputs": [],
      "source": [
        "def get_normal_KL(\n",
        "    mean_1: torch.Tensor,\n",
        "    log_std_1: torch.Tensor,\n",
        "    mean_2: Optional[torch.Tensor] = None,\n",
        "    log_std_2: Optional[torch.Tensor] = None,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    :Parameters:\n",
        "    mean_1: means of normal distributions (1)\n",
        "    log_std_1 : standard deviations of normal distributions (1)\n",
        "    mean_2: means of normal distributions (2)\n",
        "    log_std_2 : standard deviations of normal distributions (2)\n",
        "    :Outputs:\n",
        "    kl divergence of the normal distributions (1) and normal distributions (2)\n",
        "    ---\n",
        "    This function should return the value of KL(p1 || p2),\n",
        "    where p1 = Normal(mean_1, exp(log_std_1) ** 2), p2 = Normal(mean_2, exp(log_std_2) ** 2).\n",
        "    If mean_2 and log_std_2 are None values, we will use standard normal distribution.\n",
        "    Note that we consider the case of diagonal covariance matrix.\n",
        "    \"\"\"\n",
        "    if mean_2 is None:\n",
        "        mean_2 = torch.zeros_like(mean_1)\n",
        "    if log_std_2 is None:\n",
        "        log_std_2 = torch.zeros_like(log_std_1)\n",
        "    assert mean_1.shape == log_std_1.shape == mean_2.shape == log_std_2.shape\n",
        "\n",
        "    eq1 = log_std_2 - log_std_1\n",
        "    eq2 = (torch.exp(log_std_1 * 2) + (mean_1 - mean_2) ** 2) / 2 / torch.exp(log_std_2*2)\n",
        "\n",
        "    kl = eq1 + eq2 - 1/2\n",
        "\n",
        "    return kl\n",
        "\n",
        "\n",
        "def test_KL():\n",
        "    assert np.isclose(\n",
        "        get_normal_KL(\n",
        "            torch.tensor(2), torch.tensor(3), torch.tensor(0), torch.tensor(0)\n",
        "        ).numpy(),\n",
        "        200.2144,\n",
        "        rtol=1e-3,\n",
        "    )\n",
        "    assert np.isclose(\n",
        "        get_normal_KL(\n",
        "            torch.tensor(2), torch.tensor(3), torch.tensor(4), torch.tensor(5)\n",
        "        ).numpy(),\n",
        "        1.50925,\n",
        "        rtol=1e-3,\n",
        "    )\n",
        "    assert np.allclose(\n",
        "        get_normal_KL(\n",
        "            torch.tensor((10, 10)), torch.tensor((2, 4)), torch.tensor((3, 5))\n",
        "        ).numpy(),\n",
        "        [49.2990, 1498.479],\n",
        "        rtol=1e-3,\n",
        "    )\n",
        "\n",
        "\n",
        "test_KL()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IgaKKCXWVnA"
      },
      "source": [
        "$p(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4n30IYJWYpw"
      },
      "source": [
        "$\\log p(x) = -\\frac{(x - \\mu)^2}{2\\sigma^2} - \\log(\\sigma) - \\frac{1}{2}\\log(2\\pi)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "871Pfpm1TiWF"
      },
      "outputs": [],
      "source": [
        "def get_normal_nll(\n",
        "    x: torch.Tensor, mean: torch.Tensor, log_std: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    This function should return the negative log likelihood log p(x),\n",
        "    where p(x) = Normal(x | mean, exp(log_std) ** 2).\n",
        "    Note that we consider the case of diagonal covariance matrix.\n",
        "    \"\"\"\n",
        "    # eq1 = ((x - mean)**2) / (2 * torch.exp(log_std)**2)\n",
        "    # eq2 = log_std\n",
        "    # eq3 = np.log(2*np.pi)/2\n",
        "\n",
        "    # nll = eq1 + eq2+ eq3\n",
        "    # return nll\n",
        "\n",
        "    return (\n",
        "        0.5 * np.log(2 * np.pi)\n",
        "        + log_std\n",
        "        + (x - mean) ** 2 * torch.exp(-2 * log_std) * 0.5\n",
        "    )\n",
        "\n",
        "def test_NLL():\n",
        "    assert np.isclose(\n",
        "        get_normal_nll(torch.tensor(2), torch.tensor(2), torch.tensor(3)).numpy(),\n",
        "        3.9189,\n",
        "        rtol=1e-3,\n",
        "    )\n",
        "    assert np.isclose(\n",
        "        get_normal_nll(torch.tensor(5), torch.tensor(-3), torch.tensor(6)).numpy(),\n",
        "        6.9191,\n",
        "        rtol=1e-3,\n",
        "    )\n",
        "    assert np.allclose(\n",
        "        get_normal_nll(\n",
        "            torch.tensor((10, 10)), torch.tensor((2, 4)), torch.tensor((3, 5))\n",
        "        ).numpy(),\n",
        "        np.array([3.9982, 5.9197]),\n",
        "        rtol=1e-3,\n",
        "    )\n",
        "\n",
        "\n",
        "test_NLL()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ7cIAhkfhif"
      },
      "source": [
        "Let define our convolutional encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmQFoOXgAX4B"
      },
      "outputs": [],
      "source": [
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, input_shape: tuple, n_latent: int) -> None:\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.n_latent = n_latent\n",
        "        # ====\n",
        "        # your code\n",
        "        # we suggest to use the following architecture\n",
        "        # conv2d(32) -> relu -> conv(64) -> relu -> conv(128) -> relu -> conv(256) -> fc(2 * n_latent)\n",
        "        # but we encourage you to create your own architecture\n",
        "\n",
        "        # ====\n",
        "\n",
        "\n",
        "        conv_l = []\n",
        "\n",
        "        conv_l.append(nn.Conv2d(input_shape[0], 32, kernel_size=3, stride=2, padding=1))\n",
        "        conv_l.append(nn.ReLU())\n",
        "        conv_l.append(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1))\n",
        "        conv_l.append(nn.ReLU())\n",
        "        conv_l.append(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1))\n",
        "        conv_l.append(nn.ReLU())\n",
        "        conv_l.append(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1))\n",
        "        conv_l.append(nn.ReLU())\n",
        "\n",
        "        self.conv = nn.Sequential(*conv_l)\n",
        "\n",
        "\n",
        "        H, W = input_shape[1], input_shape[2]\n",
        "        self.fc_input_features = 256 * (H // 16) * (W // 16)\n",
        "        self.fc = nn.Linear(self.fc_input_features, 2 * n_latent)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple:\n",
        "        # ====\n",
        "        # your code\n",
        "        # 1) apply convs\n",
        "        # 2) reshape the output to 2d matrix for last fc layer\n",
        "        # 3) apply fc layer\n",
        "\n",
        "        # ====\n",
        "\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        mu = x[:, :self.n_latent]\n",
        "        log_std = x[:, self.n_latent:]\n",
        "\n",
        "\n",
        "        return mu, log_std\n",
        "\n",
        "\n",
        "class ConvDecoder(nn.Module):\n",
        "    def __init__(self, n_latent: int, output_shape: tuple) -> None:\n",
        "        super().__init__()\n",
        "        self.n_latent = n_latent\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "        self.base_size = (128, output_shape[1] // 8, output_shape[2] // 8)\n",
        "        # ====\n",
        "        # your code\n",
        "        # we suggest to use the following architecture\n",
        "        # fc -> conv2dtranspose(128) -> relu -> conv2dtranspose(64) -> relu\n",
        "        # -> conv2dtranspose(32) -> relu -> conv2dtranspose(3)\n",
        "        # but we encourage you to create your own architecture\n",
        "\n",
        "        # ====\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(n_latent, 128 * (output_shape[1] // 8) * (output_shape[2] // 8))\n",
        "\n",
        "        conv_l = []\n",
        "        conv_l.append(nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1))\n",
        "        conv_l.append(nn.ReLU())\n",
        "        conv_l.append(nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1))\n",
        "        conv_l.append(nn.ReLU())\n",
        "        conv_l.append(nn.ConvTranspose2d(32, output_shape[0], kernel_size=3, stride=2, padding=1, output_padding=1))\n",
        "        conv_l.append(nn.Tanh())\n",
        "        self.conv = nn.Sequential(*conv_l)\n",
        "\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        # ====\n",
        "        # your code\n",
        "        # 1) apply fc layer\n",
        "        # 2) reshape the output to 4d tensor\n",
        "        # 3) apply conv layers\n",
        "\n",
        "        # ====\n",
        "\n",
        "        z = self.fc(z)\n",
        "        z = z.view(-1, *self.base_size)\n",
        "        out = self.conv(z)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "def test_conv_models():\n",
        "    test_enc = ConvEncoder((3, 32, 32), n_latent=10)\n",
        "    inp = torch.randn((4, 3, 32, 32))\n",
        "    mu, std = test_enc(inp)\n",
        "\n",
        "    assert list(mu.shape) == [4, 10]\n",
        "    assert list(std.shape) == [4, 10]\n",
        "\n",
        "    test_dec = ConvDecoder(10, (3, 32, 32))\n",
        "    inp = torch.randn(4, 10)\n",
        "    assert list(test_dec(inp).shape) == [4, 3, 32, 32]\n",
        "\n",
        "\n",
        "test_conv_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXtOjEvbftM9"
      },
      "source": [
        "Now it is time to implement VAE model for image dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3T4RRzUfrdg"
      },
      "outputs": [],
      "source": [
        "class ConvVAE(nn.Module):\n",
        "    def __init__(self, input_shape: tuple, n_latent: int, beta: float = 1) -> None:\n",
        "        super().__init__()\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.n_latent = n_latent\n",
        "        self.beta = beta\n",
        "\n",
        "        self.init_submodels()\n",
        "\n",
        "    def init_submodels(self):\n",
        "        # ====\n",
        "        # your code\n",
        "        # define encoder with input size input_shape and output dim n_latent\n",
        "        # define decoder with input dim n_latent and output size input_shape\n",
        "\n",
        "        # ====\n",
        "        self.encoder = ConvEncoder(self.input_shape, self.n_latent)\n",
        "        self.decoder = ConvDecoder(self.n_latent, self.input_shape)\n",
        "\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def prior(self, n: int) -> torch.Tensor:\n",
        "        # ====\n",
        "        # your code\n",
        "        # return n samples from prior distribution (we use standart normal for prior)\n",
        "\n",
        "        # ====\n",
        "        z = torch.randn(n, self.n_latent)\n",
        "\n",
        "        z = z.to(self.device)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple:\n",
        "        # ====\n",
        "        # your code\n",
        "        # 1) apply encoder to get mu_z, log_std_z\n",
        "        # 2) apply reparametrization trick (use self.prior)\n",
        "        # 3) apply decoder to get mu_x (which corresponds to reconstructed x)\n",
        "        mu_z, log_std_z = self.encoder(x)\n",
        "        z = self.prior(mu_z.shape[0]) * torch.exp(log_std_z) + mu_z\n",
        "        x_recon = self.decoder(z)\n",
        "\n",
        "\n",
        "        # ====\n",
        "        return mu_z, log_std_z, x_recon\n",
        "\n",
        "\n",
        "    def loss(self, x: torch.Tensor) -> dict:\n",
        "        mu_z, log_std_z, x_recon = self.forward(x)\n",
        "\n",
        "        x_flat = x.view(x.size(0), -1)\n",
        "        x_recon_flat = x_recon.view(x_recon.size(0), -1)\n",
        "        log_std = torch.zeros_like(x_recon_flat)\n",
        "\n",
        "        recon_loss = get_normal_nll(x_flat, x_recon_flat, log_std).sum(dim=1).mean()\n",
        "\n",
        "        kl_loss = get_normal_KL(mu_z, log_std_z).sum(dim=1).mean()\n",
        "\n",
        "        return {\n",
        "            \"elbo_loss\": recon_loss + self.beta * kl_loss,\n",
        "            \"recon_loss\": recon_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }\n",
        "\n",
        "\n",
        "    def sample(self, n: int) -> np.ndarray:\n",
        "        with torch.no_grad():\n",
        "            # ====\n",
        "            # your code\n",
        "            # 1) generate prior samples\n",
        "            # 2) apply decoder\n",
        "\n",
        "            # ====\n",
        "\n",
        "            z = self.prior(n)\n",
        "            x_recon = self.decoder(z)\n",
        "\n",
        "            samples = torch.clamp(x_recon, -1, 1)\n",
        "        return samples.cpu().numpy() * 0.5 + 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxxxclgEAX6a"
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# your code\n",
        "# choose these parameters\n",
        "\n",
        "BATCH_SIZE = 32   # any adequate value\n",
        "EPOCHS = 16     # < 16\n",
        "LR = 1e-3          # < 1e-3\n",
        "N_LATENS = 1024  # 128 < _ < 1024\n",
        "BETA = 1        # 0.1 < _ < 10\n",
        "# ====\n",
        "\n",
        "# we center the data, because it helps the model to fit\n",
        "centered_train_data = train_data * 2 - 1\n",
        "centered_test_data = test_data * 2 - 1\n",
        "\n",
        "train_loader = data.DataLoader(centered_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(centered_test_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "model = ConvVAE((3, 32, 32), N_LATENS, BETA)\n",
        "\n",
        "train_losses, test_losses = train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=EPOCHS,\n",
        "    lr=LR,\n",
        "    loss_key=\"elbo_loss\",\n",
        "    use_tqdm=True,\n",
        "    use_cuda=USE_CUDA,\n",
        ")\n",
        "for key, value in test_losses.items():\n",
        "    print(\"{}: {:.4f}\".format(key, value[-1]))\n",
        "plot_training_curves(train_losses, test_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlE8JlD-f1B9"
      },
      "source": [
        "Now we could visualize the model outputs.\n",
        "\n",
        "1. We could sample new images from our model (sample latent variable from the prior and apply the decoder).\n",
        "2. We could visualize image reconstructions (apply the encoder and the decoder to the fixed image).\n",
        "3. Visualize interpolations (apply the encoder to two images $\\mathbf{x}_1$ and $\\mathbf{x}_2$ to obtain the latent variables $\\mathbf{z}_1$ and $\\mathbf{z}_2$, apply the decoder to the latent variables $\\mathbf{z}$ lying on the segment between $\\mathbf{z}_1$ and $\\mathbf{z}_2$).\n",
        "\n",
        "**Note:** it is ok, that your samples are blurry. We do not use difficult architectures and do not tune hyperparameters carefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lpr1ckHAd2v"
      },
      "outputs": [],
      "source": [
        "samples = model.sample(100)\n",
        "\n",
        "x = next(iter(test_loader))[:50]\n",
        "\n",
        "x = x.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z, _ = model.encoder(x)\n",
        "    x_recon = torch.clamp(model.decoder(z), -1, 1)\n",
        "reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32) * 0.5 + 0.5\n",
        "reconstructions = reconstructions.cpu().numpy()\n",
        "\n",
        "x = next(iter(test_loader))[:20]\n",
        "x = x.to(model.device)\n",
        "with torch.no_grad():\n",
        "    z, _ = model.encoder(x)\n",
        "    z1, z2 = z.chunk(2, dim=0)\n",
        "    interps = [\n",
        "        model.decoder(z1 * (1 - alpha) + z2 * alpha) for alpha in np.linspace(0, 1, 10)\n",
        "    ]\n",
        "    interps = torch.stack(interps, dim=1).view(-1, 3, 32, 32)\n",
        "    interps = torch.clamp(interps, -1, 1) * 0.5 + 0.5\n",
        "interps = interps.cpu().numpy()\n",
        "\n",
        "show_samples(reconstructions, \"CIFAR10 reconstructions\")\n",
        "show_samples(samples, \"CIFAR10 samples\")\n",
        "show_samples(interps, \"CIFAR10 interpolation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12ZdDvZXFh1"
      },
      "source": [
        "## Task 3: ResNetVAE on CIFAR10 data (4pt)\n",
        "\n",
        "Now we will try to make our architecture more powerful. Let try to use ResNet-like encoder and decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh_rTk9wm9yv"
      },
      "source": [
        "First of all let define basic ResNet block. It will be the basic block for our encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBZA5vBwf0c-"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, final_relu=True):\n",
        "        super().__init__()\n",
        "        self.final_relu = final_relu\n",
        "        # ====\n",
        "        # your code\n",
        "        # here you could try different network structures\n",
        "        # we suggest to use the following:\n",
        "        # residual(x) = conv(bn(relu(conv(bn(x)))))\n",
        "        # output = relu(conv1x1(input) + residual(input))\n",
        "\n",
        "        # ====\n",
        "\n",
        "        padding = (kernel_size - 1) // 2\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
        "\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ====\n",
        "        # your code\n",
        "        residual = self.bn1(x)\n",
        "        residual = self.conv1(residual)\n",
        "        residual = self.relu1(residual)\n",
        "        residual = self.bn2(residual)\n",
        "        residual = self.conv2(residual)\n",
        "\n",
        "\n",
        "        result = self.conv1_1(x) + residual\n",
        "        # ====\n",
        "        if self.final_relu:\n",
        "            result = self.relu2(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "def test_resnet_block():\n",
        "    test_inp = torch.randn(5, 64, 128, 128)\n",
        "\n",
        "    for out_channels in [64, 128]:\n",
        "        for kernel_size in [3, 5, 7]:\n",
        "            for stride in [1, 2, 4]:\n",
        "                resnet_block = ResNetBlock(in_channels=64, out_channels=out_channels,\n",
        "                                        kernel_size=kernel_size, stride=stride)\n",
        "                assert list(resnet_block(test_inp).shape) == [5, out_channels, 128 // stride, 128 // stride]\n",
        "\n",
        "\n",
        "test_resnet_block()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5njl8CQpvqw"
      },
      "source": [
        "Now let define basic ResNet block. It will be the basic block for our decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19M3VevKYCrn"
      },
      "outputs": [],
      "source": [
        "class ResNetTransposeBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, final_relu=True):\n",
        "        super().__init__()\n",
        "        self.final_relu = final_relu\n",
        "        # ====\n",
        "        # your code\n",
        "        # here you could try different network structures\n",
        "        # we suggest to use the following:\n",
        "        # output = conv(bn(f(input))) + f(input), where:\n",
        "        # f(x) = upconv(bn(x))\n",
        "\n",
        "\n",
        "        padding = (kernel_size - stride) // 2\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv1 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "\n",
        "        # ====\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ====\n",
        "        # your code\n",
        "        f = self.upconv(self.bn1(x))\n",
        "\n",
        "        conv = self.conv1(self.bn2(f))\n",
        "\n",
        "        result = conv + f\n",
        "        # ====\n",
        "        if self.final_relu:\n",
        "            result = self.relu1(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "def test_resnet_transposed_block():\n",
        "    test_inp = torch.randn(5, 64, 64, 64)\n",
        "    for out_channels in [64, 128]:\n",
        "        for kernel_size in [4, 6, 8]:\n",
        "            for stride in [2, 4]:\n",
        "                resnet_block = ResNetTransposeBlock(\n",
        "                    in_channels=64, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "                assert list(resnet_block(test_inp).shape) == [5, out_channels, 64 * stride, 64 * stride]\n",
        "\n",
        "\n",
        "test_resnet_transposed_block()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAYKzNCqp2o-"
      },
      "source": [
        "Now we are to define our encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFkDOrg7YVrB"
      },
      "outputs": [],
      "source": [
        "class ConvResNetEncoder(nn.Module):\n",
        "    def __init__(self, input_shape, n_latent):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.n_latent = n_latent\n",
        "        # ====\n",
        "        # your code\n",
        "        # our suggestions:\n",
        "        # - try to combine multiple resnet blocks\n",
        "        # - place Flatten + Linear at the end\n",
        "\n",
        "        # ====\n",
        "\n",
        "        self.conv = nn.Conv2d(input_shape[0], 64, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.block1 = ResNetBlock(in_channels=64, out_channels=64, kernel_size=3, stride=2)\n",
        "        self.block2 = ResNetBlock(in_channels=64, out_channels=128, kernel_size=3, stride=2)\n",
        "        self.block3 = ResNetBlock(in_channels=128, out_channels=128, kernel_size=3, stride=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        # self.fc = nn.Linear(128 * 4 * 4, n_latent * 2)\n",
        "\n",
        "        H, W = input_shape[1], input_shape[2]\n",
        "        self.fc_input_features = 128 * (H // 16) * (W // 16)\n",
        "        self.fc = nn.Linear(self.fc_input_features, 2 * n_latent)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ====\n",
        "        # your code\n",
        "        # apply all blocks defined in init\n",
        "        # split output tensor to mu and log_std\n",
        "\n",
        "        # ====\n",
        "\n",
        "        x = self.conv(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        mu = x[:, :self.n_latent]\n",
        "        log_std = x[:, self.n_latent:]\n",
        "\n",
        "        return mu, log_std\n",
        "\n",
        "\n",
        "class ConvResNetDecoder(nn.Module):\n",
        "    def __init__(self, n_latent, output_shape):\n",
        "        super().__init__()\n",
        "        self.n_latent = n_latent\n",
        "        self.output_shape = output_shape\n",
        "        # ====\n",
        "        # your code\n",
        "        # our suggestions:\n",
        "        # - apply linear layer to the input\n",
        "        # - reshape output matrix to 4-dims tensor\n",
        "        # - try to combine multiple resnet transposed blocks\n",
        "\n",
        "        # ====\n",
        "        self.base_size = (128, output_shape[1] // 8, output_shape[2] // 8)\n",
        "\n",
        "        self.fc = nn.Linear(n_latent, 128 * (output_shape[1] // 8) * (output_shape[2] // 8))\n",
        "        self.block1 = ResNetTransposeBlock(in_channels=128, out_channels=128, kernel_size=4, stride=2)\n",
        "        self.block2 = ResNetTransposeBlock(in_channels=128, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.block3 = ResNetTransposeBlock(in_channels=64, out_channels=64, kernel_size=4, stride=2)\n",
        "\n",
        "        self.conv = nn.Conv2d(64, output_shape[0], kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        # ====\n",
        "        # your code\n",
        "        # apply all blocks defined in init\n",
        "\n",
        "        # ====\n",
        "\n",
        "        z = self.fc(z)\n",
        "        z = z.view(-1, *self.base_size)\n",
        "        z = self.block1(z)\n",
        "        z = self.block2(z)\n",
        "        z = self.block3(z)\n",
        "        out = self.conv(z)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def test_convresnet_models():\n",
        "    test_enc = ConvResNetEncoder((3, 32, 32), n_latent=10)\n",
        "    inp = torch.randn((4, 3, 32, 32))\n",
        "    mu, std = test_enc(inp)\n",
        "\n",
        "    assert list(mu.shape) == [4, 10]\n",
        "    assert list(std.shape) == [4, 10]\n",
        "\n",
        "    test_dec = ConvResNetDecoder(10, (3, 32, 32))\n",
        "    inp = torch.randn(4, 10)\n",
        "    assert list(test_dec(inp).shape) == [4, 3, 32, 32]\n",
        "\n",
        "\n",
        "test_convresnet_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVUixHmiquLu"
      },
      "source": [
        "Our new VAE model will be almost the same as the previous one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAVnmVkbakYt"
      },
      "outputs": [],
      "source": [
        "class ConvResNetVAE(ConvVAE):\n",
        "    def init_submodels(self):\n",
        "        # ====\n",
        "        # your code\n",
        "        # it is the only method that we have to redefine\n",
        "\n",
        "        # ====\n",
        "\n",
        "        self.encoder = ConvResNetEncoder(self.input_shape, self.n_latent)\n",
        "        self.decoder = ConvResNetDecoder(self.n_latent, self.input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxeq_hyUqzuk"
      },
      "source": [
        "That is all! We are ready to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr9PNknYaLTx"
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# your code\n",
        "# choose these parameters\n",
        "\n",
        "BATCH_SIZE = 32   # any adequate value\n",
        "EPOCHS =  16     # < 16\n",
        "LR =  1e-3         # < 1e-3\n",
        "N_LATENS = 1024    # 128 < _ < 1024\n",
        "BETA =  1       # 0.1 < _ < 10\n",
        "# ====\n",
        "\n",
        "# we center the data, because it helps the model to fit\n",
        "centered_train_data = train_data * 2 - 1\n",
        "centered_test_data = test_data * 2 - 1\n",
        "\n",
        "train_loader = data.DataLoader(centered_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(centered_test_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "model = ConvResNetVAE((3, 32, 32), N_LATENS, BETA)\n",
        "\n",
        "train_losses, test_losses = train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=EPOCHS,\n",
        "    lr=LR,\n",
        "    loss_key=\"elbo_loss\",\n",
        "    use_tqdm=True,\n",
        "    use_cuda=USE_CUDA,\n",
        ")\n",
        "for key, value in test_losses.items():\n",
        "    print(\"{}: {:.4f}\".format(key, value[-1]))\n",
        "plot_training_curves(train_losses, test_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AlBOAuxq5Xd"
      },
      "source": [
        "Let visualize model samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYQWcZ02aq9X"
      },
      "outputs": [],
      "source": [
        "samples = model.sample(100)\n",
        "\n",
        "x = next(iter(test_loader))[:50]\n",
        "\n",
        "x = x.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z, _ = model.encoder(x)\n",
        "    x_recon = torch.clamp(model.decoder(z), -1, 1)\n",
        "reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32) * 0.5 + 0.5\n",
        "reconstructions = reconstructions.cpu().numpy()\n",
        "\n",
        "x = next(iter(test_loader))[:20]\n",
        "x = x.to(model.device)\n",
        "with torch.no_grad():\n",
        "    z, _ = model.encoder(x)\n",
        "    z1, z2 = z.chunk(2, dim=0)\n",
        "    interps = [model.decoder(z1 * (1 - alpha) + z2 * alpha) for alpha in np.linspace(0, 1, 10)]\n",
        "    interps = torch.stack(interps, dim=1).view(-1, 3, 32, 32)\n",
        "    interps = torch.clamp(interps, -1, 1) * 0.5 + 0.5\n",
        "interps = interps.cpu().numpy()\n",
        "\n",
        "show_samples(reconstructions, 'CIFAR10 reconstructions')\n",
        "show_samples(samples, 'CIFAR10 samples')\n",
        "show_samples(interps, 'CIFAR10 interpolation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbpEDMBKq8yb"
      },
      "source": [
        "Try to compare values of losses and samples for ConvVAE and ConvResNetVAE."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}